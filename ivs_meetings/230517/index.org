#+AUTHOR: Philipp Denzel
#+TITLE: IVS group meeting
#+DATE: 2023/05/17 Wed - ZHAW

# #+OPTIONS: author:nil
# #+OPTIONS: email:nil
# #+OPTIONS: \n:t
# #+OPTIONS: date:nil
#+OPTIONS: toc:1
#+OPTIONS: num:nil
# #+OPTIONS: toc:nil
#+OPTIONS: timestamp:nil
#+PROPERTY: eval no

# #+OPTIONS: reveal_single_file: t

# --- Configuration - more infos @ https://revealjs.com/config/
# --- General behaviour
#+REVEAL_INIT_OPTIONS: width: 1920, height: 1080, center: true, margin: 0.05,
#+REVEAL_INIT_OPTIONS: minScale: 0.2, maxScale: 4.5,
#+REVEAL_INIT_OPTIONS: progress: true, history: false, slideNumber: false,
#+REVEAL_INIT_OPTIONS: controls: true, keyboard: true, previewLinks: true, 
#+REVEAL_INIT_OPTIONS: mathjax: true,
#+REVEAL_INIT_OPTIONS: transition: 'fade',
#+REVEAL_INIT_OPTIONS: navigationMode: 'default'
# #+REVEAL_INIT_OPTIONS: navigationMode: 'linear',
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="">
#+REVEAL_POSTAMBLE: <p> Created by phdenzel. </p>

# --- Javascript
#+REVEAL_PLUGINS: ( markdown math zoom )
# #+REVEAL_EXTRA_JS: { src: 'vid.js', async: true, condition: function() { return !!document.body.classList; } }

# --- Theming
#+REVEAL_THEME: phdcolloq
# #+REVEAL_THEME: white

# --- CSS
#+REVEAL_EXTRA_CSS: ./assets/css/slides.css
#+REVEAL_EXTRA_CSS: ./assets/css/header.css
#+REVEAL_EXTRA_CSS: ./assets/css/footer.css
#+REVEAL_SLIDE_HEADER: <div style="height:100px"></div>
#+REVEAL_SLIDE_FOOTER: <div style="height:100px"></div>
#+REVEAL_HLEVEL: 2

# --- Macros
# --- example: {{{color(red,This is a sample sentence in red text color.)}}}
#+MACRO: NL @@latex:\\@@ @@html:<br>@@ @@ascii:|@@
#+MACRO: quote @@html:<q cite="$2">$1</q>@@ @@latex:``$1''@@
#+MACRO: color @@html:<font color="$1">$2</font>@@
#+MACRO: h1 @@html:<h1>$1</h1>@@
#+MACRO: h2 @@html:<h2>$1</h2>@@
#+MACRO: h3 @@html:<h3>$1</h3>@@
#+MACRO: h4 @@html:<h4>$1</h4>@@


#+begin_comment
For export to a jekyll blog (phdenzel.github.io) do

1) generate directory structure in assets/blog-assets/post-xyz/
├── slides.html
├── assets
│   ├── css
│   │   ├── reveal.css
│   │   ├── print
│   │   └── theme
│   │       ├── phdcolloq.css
│   │       └── fonts
│   │           ├── league-gothic
│   │           └── source-sans-pro
│   ├── images
│   ├── js
│   │   ├── reveal.js
│   │   ├── markdown
│   │   ├── math
│   │   ├── notes
│   │   └── zoom
│   └── movies
└── css
    └── _style.sass

2)  change the linked css and javascript files to local copies

<link rel="stylesheet" href="file:///home/phdenzel/local/reveal.js/dist/reveal.css"/>
<link rel="stylesheet" href="file:///home/phdenzel/local/reveal.js/dist/theme/phdcolloq.css" id="theme"/>
<script src="/home/phdenzel/local/reveal.js/dist/reveal.js"></script>
<script src="file:///home/phdenzel/local/reveal.js/plugin/markdown/markdown.js"></script>
<script src="file:///home/phdenzel/local/reveal.js/plugin/math/math.js"></script>
<script src="file:///home/phdenzel/local/reveal.js/plugin/zoom/zoom.js"></script>

to

<link rel="stylesheet" href="./assets/css/reveal.css"/>
<link rel="stylesheet" href="./assets/css/theme/phdcolloq.css" id="theme"/>

<script src="./assets/js/reveal.js"></script>
<script src="./assets/js/markdown/markdown.js"></script>
<script src="./assets/js/math/math.js"></script>
<script src="./assets/js/zoom/zoom.js"></script>
#+end_comment



# ------------------------------------------------------------------------------

# #+REVEAL_TITLE_SLIDE: <div style="padding: 0px 30px 250px 30px"> <a href='https://www.uzh.ch/de.html'> <img src='./assets/images/uzh_logo_d_neg_retina.png' alt='UZH logo' width='294px' height='100px' style="float: left"> </a> </div>
#+REVEAL_TITLE_SLIDE: <h1>%t</h1>
#+REVEAL_TITLE_SLIDE: <h3>on my SKACH project(s)</h3>
#+REVEAL_TITLE_SLIDE: <h3>%s</h3>
#+REVEAL_TITLE_SLIDE: <div style="padding-top: 50px">%d</div>
#+REVEAL_TITLE_SLIDE: <div style="padding-top: 50px">by</div>
#+REVEAL_TITLE_SLIDE: <h4 style="padding-top: 50px; padding-left: 200px;"><a href="mailto:phdenzel@gmail.com"> %a </a> <img src="./assets/images/contact_qr.png" alt="contact_qr.png" height="150px" align="center" style="padding-left: 50px;"></h4>
#+REVEAL_TITLE_SLIDE_BACKGROUND: ./assets/images/poster_skach_skao.png
#+REVEAL_TITLE_SLIDE_BACKGROUND_SIZE: contain
#+REVEAL_TITLE_SLIDE_BACKGROUND_OPACITY: 0.6

#+BEGIN_NOTES
Title slide
#+END_NOTES

#+REVEAL_TOC_SLIDE_BACKGROUND_SIZE: 500px


* (Recap)
:PROPERTIES:
:REVEAL_EXTRA_ATTR: class="upperh" data-background-video="./assets/movies/radio_dish_scheme.mp4" data-background-video-loop data-background-video-muted data-background-size="contain";
:END:

{{{NL}}}
{{{NL}}}
{{{NL}}}
{{{NL}}}
\begin{equation}
  V_{pq} = \int_{4\pi} g_{p}(r)\ B(r)\ g^{\ast}_{q}(r) e^{-\frac{2\pi}{\lambda}\langle\vec{p}-\vec{q}, \vec{r}\rangle} \text{d}\Omega
\end{equation}
{{{NL}}}
{{{NL}}}
{{{NL}}}
{{{NL}}}
{{{NL}}}
{{{NL}}}
{{{NL}}}


** The infamous visibilities and "uv" plane

- As an inverse problem:
  - $$V = \Psi^{\ast} B \Psi$$
  - $$\tilde{B} = \tilde{\Psi} V \tilde{\Psi}^{\ast}$$
- Eigenvalue decomposition:
  - $$\tilde{B} = \sum_{i} \lambda_{i} ||\Psi v_{i}||^{2}$$

#+ATTR_HTML: :width 510px :align left :style float:right :style padding: 0px 100px 10px 0px;
[[./assets/images/ska/Mid_layout.png]] {{{NL}}}

#+ATTR_HTML: :width 500px :align left :style float:right :style padding: 0px 10px 10px 0px;
[[./assets/images/radio_schematics/uv_matrix_bluebild.png]] {{{NL}}}
Credit: E. Tolley (EPFL)


** Dirty images

#+ATTR_HTML: :width 800px :align center :style float:center :style padding: 0px 10px 10px 0px;
#+CAPTION: Credit: E. Tolley (EPFL)
[[./assets/images/radio_schematics/dirty_image.png]]


** Training data from simulations
:PROPERTIES:
:REVEAL_EXTRA_ATTR: class="upperh" data-background-video="./assets/movies/illustris/tng50_single_galaxy_formation_g1_1080p.mp4#t=18.5" data-background-video-muted data-background-size="contain" data-background-opacity="0.8"
:END:

# #+REVEAL_HTML: <video width="1920" height="auto" style="max-height:75vh" data-autoplay controls>
# #+REVEAL_HTML:   <source src="./assets/movies/illustris/tng50_single_galaxy_formation_g1_1080p.mp4#t=18.5" type="video/mp4" />
# #+REVEAL_HTML: </video>

#+ATTR_HTML: :class footer-item
g1 (TNG50), Credit: IllustrisTNG


** Data formats

- point clouds (3D coordinates: x, y, z)
- lightcones (2D images + 1D time: \theta, \phi, frequency)
- visibilities (telescope data cubes using OSKAR)
- images (3D projections from visibilities and/or simulations)


** Pix2Pix

- [[https://github.com/phillipi/pix2pix][pix2pix by I. Phillipi]] (in lua torch)
  - difference: W-GAN penalty (replace KL divergence with Wasserstein metric)
    - limit discriminator to 1-Lipschitz function (learned)
- [[https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix][pix2pix+cycleGAN by J.-Y. Zhu]] (in pytorch)
- [[https://affinelayer.com/pix2pix/][blog post by Ch. Hesse]] (pix2pix vs. CycleGAN)

#+REVEAL: split
  
#+ATTR_HTML: :height 800px :style background-color: #888888;
[[./assets/images/pix2pix/pix2pix_generator_training.webp]]

#+REVEAL: split

#+ATTR_HTML: :height 800px :style background-color: #888888;
[[./assets/images/pix2pix/pix2pix_discriminator_training.webp]]


** My development process

- Prepare the dataset & dataloader
- Test driven development (mantra: "Guilty until proven innocent!"):
  - first write tests, then implement accordingly
  - for existing code: write tests for modules, in order to understand
- UNet generators vs. ResNet generators
- PixelGAN vs. PatchGAN


** ML4GLEAM project

- project idea by Michele Bianco (EPFL) & Philipp Denzel (ZHAW):
  - classification engine for extragalactic sources, tested on the GLEAM survey

#+REVEAL: split

#+ATTR_HTML: :height 1000px :style float:left :style margin:2px 2px 2px 200px;
#+CAPTION: Credit: @@html:<a href="https://iopscience.iop.org/article/10.1088/0004-637X/723/1/620">Wang et al. (2010)</a>@@
[[./assets/images/sdc3a/sources_wang+.png]]

#+REVEAL: split

- find help:
  - Elena found an interested person, Michele still searching for EPFL student
  - assists for paper: Mark Sargent (ISSI, Bern) & Anna Bonaldi (SKAO, Manchester)


*** GLEAM
:PROPERTIES:
:REVEAL_EXTRA_ATTR: class="upperlefth" data-background-iframe="https://gleamoscope.icrar.org/gleamoscope/trunk/src/" data-background-interactive;
:END:


*** test dataset

1) [X] image downloader: FITS files for each frequency band
2) [ ] convert coordinate system of FITS files ZEA @@html:&#x27F6;@@ ICRS
3) [X] get catalog for extragalactic source positions


*** training dataset

1) [-] check literature (more recent papers not yet found)
   - [X] [[https://iopscience.iop.org/article/10.1088/0004-637X/723/1/620][Wang et al. (2010)]] section 2.3
   - [X] [[https://academic.oup.com/mnras/article/389/3/1319/1019026?login=true][Jélic et al. (2008)]] section 4
   - [X] [[https://academic.oup.com/mnras/article/391/1/383/1125147?login=true][Gleser et al. (2008)]] section 4.2
2) [ ] meeting with Mark Sargent (ISSI) & Anna Bonaldi (SKAO)
3) [ ] get USHUU halo catalog (relevant redshifts?)
4) [ ] apply models to halo catalog
5) [ ] create lightcone (frequency evolution of radio sources)
   - @@html:&#x27F6;@@ target catalog (positions)
6) [ ] use OSKAR/Karabo for mock observation and systematics


*** ML setup

1) [ ] decide on task (classification, classification+localization)
2) [ ] find architecture: any ideas?
3) [ ] possibility of cross-referencing with other surveys
   - i.e. include priors @@html:&#x27F6;@@ Bayesian CNNs?
4) [ ] explainability of the model is important (audience: astronomers)


*** Bayesian neural nets

{{{h4(Classically discrete)}}}

#+begin_src dot :file assets/images/neural_net_scheme.png :cmdline -Kdot -Tpng :exports results
  digraph NeuralNet {
      // General settings
      rankdir=LR
      fontname="Helvetica,Arial,sans-serif"
      fontcolor=black
      splines=false
      node [
          fontname="Helvetica,Arial,sans-serif"
          fontcolor=black
          style=filled
          shape=record
      ]
      edge [ 
          fontname="Helvetica,Arial,sans-serif"
          fontcolor=black
      ]

      // Nodes
      X1 [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>x1</td> <td>...</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      X2 [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>x2</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      Y [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>y</td> </tr>
                 </table>> ];
      L1 [fillcolor="#f1b441"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>tanh</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      L2 [fillcolor="#f1b441"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>ReLU</td> </tr>
                 </table>> ];
      W1 [fillcolor="#CC6677"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>w1</td> <td>...</td> <td>...</td> </tr>
                  <tr> <td>...</td> <td>...</td> <td>...</td> </tr>
                  <tr> <td>...</td> <td>...</td> <td>...</td> </tr>
                  <tr> <td>...</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      W2 [fillcolor="#CC6677"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>w2</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      B1 [fillcolor="#44AA99"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>b1</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      B2 [fillcolor="#44AA99"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>b2</td> </tr>
                 </table>> ];
      // NN
      X1 -> W1[label="*"];
      W1 -> B1[label="+"];
      B1 -> L1[label=":"];
      L1 -> X2;
      X2 -> W2[label="*"];
      W2 -> B2[label="+"]
      B2 -> L2[label=":"];
      L2 -> Y;

  }
#+end_src

#+RESULTS:
[[file:assets/images/neural_net_scheme.png]]


{{{h4(Going Bayesian)}}}

#+begin_src dot :file assets/images/bayesian_nn_scheme.png :cmdline -Kdot -Tpng :exports results
  digraph NeuralNet {
      // General settings
      rankdir=LR
      fontname="Helvetica,Arial,sans-serif"
      fontcolor=black
      splines=false
      node [
          fontname="Helvetica,Arial,sans-serif"
          fontcolor=black
          style=filled
          shape=record
      ]
      edge [ 
          fontname="Helvetica,Arial,sans-serif"
          fontcolor=black
      ]

      // Nodes
      X1 [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>x1</td> <td>...</td> <td>...</td> <td>...</td> </tr>
                 </table>> ];
      X2 [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>x2</td> <td>~</td> <td>~</td> </tr>
                 </table>> ];
      L1 [fillcolor="#f1b441"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>tanh</td> <td>~</td> <td>~</td> </tr>
                 </table>> ];
      L2 [fillcolor="#f1b441"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>ReLU</td> </tr>
                 </table>> ];
      W1 [fillcolor="#CC6677"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>w1</td> <td>~</td> <td>~</td> </tr>
                  <tr> <td>~</td> <td>~</td> <td>~</td> </tr>
                  <tr> <td>~</td> <td>~</td> <td>~</td> </tr>
                  <tr> <td>~</td> <td>~</td> <td>~</td> </tr>
                 </table>> ];
      W2 [fillcolor="#CC6677"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>w2</td> <td>~</td> <td>~</td> </tr>
                 </table>> ];
      B1 [fillcolor="#44AA99"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>b1</td> <td>~</td> <td>~</td> </tr>
                 </table>> ];
      B2 [fillcolor="#44AA99"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>b2</td> </tr>
                 </table>> ];
      Y [fillcolor="#DDDDDD"
          label=<<table border="0" cellborder="1" cellspacing="0" cellpadding="4">
                  <tr> <td>P(y\|x)</td> </tr>
                 </table>> ];
      // NN
      X1 -> W1[label="*"];
      W1 -> B1[label="+"];
      B1 -> L1[label=":"];
      L1 -> X2;
      X2 -> W2[label="*"];
      W2 -> B2[label="+"]
      B2 -> L2[label=":"];
      L2 -> Y;

  }
#+end_src

#+RESULTS:
[[file:assets/images/bayesian_nn_scheme.png]]




* Ongoing work for SKA

#+begin_src emacs-lisp :exports none :results none
  (setq org-html-checkbox-type 'html)
#+end_src

Testing generative models for the SKA project:

- [X] Adversarial models: 
  - [X] CycleGAN
  - [X] Pix2pix
- [ ] Flow-based generative models
- [ ] Diffusion models


** Data versioning: testing ~oxen~ against ~dvc~

- on dataset: *ImageNet* (Winter 2021) with ~zsh~'s ~time~ macro
- on archlinux 6.2.10-arch1-1 / Intel i7-7700K / 64 GB DDR3 / ext4 / SATA: 6GB/s & 256 MB Cache

#+attr_html: :style border:0.1px solid; margin-top: 30px; text-align: right;
|---+--------+----------------------+-----------------------|
|   |  cmd   | dvc timing [s] @ CPU | oxen timing [s] @ CPU |
|---+--------+----------------------+-----------------------|
| ! |  <c>   |                  <r> |                   <r> |
|   |  init  |            1.8 @ 68% |             3.6 @ 12% |
|   |  add   |        98384.0 @ 48% |         35331.8 @ 50% |
|   | commit |        81091.1 @ 27% |         58425.7 @ 16% |
|   |  push  |                  nil |                   nil |
|---+--------+----------------------+-----------------------|

- My opinion: ~oxen~ is simple, and all I am looking for
  - ~oxen~ is faster, but only marginally in practice
  - ~dvc~ integrates more features (but mostly useless)


** Update: data versioning

- Experiment
  1) changing individual images
     - 200 random samples
     - blacking out 8x8 patch at the top left corner
  2) adding & commiting the changes
     - ~dvc~: roughly 20 hours / ~oxen~: roughly 15 hours
- I can't recommend any tool for truly large datasets (-> 1B samples/~1TB)
  - ~status~ check takes roughly 4-6 hours for either tool (~oxen~, ~dvc~)


** BTW...! archlinux adopted Python 3.11 two weeks ago

- consistent speed-up between 20%-80%

#+ATTR_HTML: :height 800px :align center :style float:center
[[./assets/images/python/python_3.11.png]]


** HDF5/h5py for pytorch datasets

#+ATTR_HTML: :height 300px :align left :style float:left :style padding: 0px 50px 10px 250px;
[[./assets/images/hdf5/HDF_logo.png]]
#+ATTR_HTML: :height 100px :align left :style float:left :style padding: 75px 10px 10px 10px;
[[./assets/images/hdf5/ampersand.png]]
#+ATTR_HTML: :height 350px :align left :style float:right :style padding: 0px 0px 10px 50px;
[[./assets/images/python/Python_logo.png]]
#+ATTR_HTML: :height 300px :align left :style float:right :style padding: 0px 0px 10px 50px;
[[./assets/images/python/pytorch_icon.png]]


*** HDF5: filesystem analogue

#+ATTR_HTML: :height 800px :align center :style float:center
[[./assets/images/hdf5/like_a_filesystem.png]]


*** HDF5 scheme

- Groups:
  - provide structure
  - POSIX like paths, e.g. ~/simulations/0001/images~, etc.
- Datasets
  - arrays of many data types, e.g. i32, f64, byte strings, etc.
  - storage layouts: contiguous or chunked
  - optimization filters, e.g. compression, shuffling, or checksums
- Attributes
  - metadata (hash map)
  - arbitrary types, up to 64KB


*** HDF5 chunking

#+ATTR_HTML: :height 800px :align center :style float:center
[[./assets/images/hdf5/storage_layouts.png]]


*** h5py

#+begin_src python
  # write HDF5 dataset
  with h5py.File(filename, mode='w',
                 rdcc_nbytes=(1<<30),  # 1<<20 = 1MB, 1<<30 = 1GB
                 rdcc_w0=1,            # FIFO=0, FIFO+complete=1
                 rdcc_nslots=10111     # prime, 10-100 times number of chunks
                 ) as h5:
      h5.create_group('/domainA')
      # add dataset at /domainA/images
      h5.create_dataset('images', data=domainA_array, chunks=(64, 512, 512),
                        compression='lzf', shuffle=True))
      h5.create_group('/domainB')
      # add dataset at /domainB/images
      h5.create_dataset('images', data=domainB_array, chunks=(64, 512, 512),
                        compression='lzf', shuffle=True))
#+end_src

*** Problem: Dataloaders don't like h5py.Files

- ~Dataset~ instances are passed to ~DataLoader~
- ~DataLoader~ need ~Dataset~ instances to be serializeable for that
- Problem: open ~h5py.Files~ can't be pickled, i.e. no serialization
- Solution: lazy-loading the ~h5py.File~ in ~Dataset~ instance


*** h5py + torch.utils.data.Dataset

#+begin_src python
  class H5Dataset(Dataset):
      def __init__(self, h5_path, group):
          self.h5_path = h5_path
          self.group = group
          self._h5 = None
          self.length = self.h5[f"/{self.group}/dataset"].shape[0]
          self._h5 = None  # GC will take care of it...

      @property
      def h5(self):
          if self._h5 is None:  # lazy loading here!
              self._h5 = h5py.File(self.h5_path, "r")
          return self._h5

      def __getitem__(self, index):
          dataset = self.h5[f"/{self.group}/images"]
          data = torch.from_numpy(dataset[index, ...])
          metadata = self.h5[f"/{self.group}/metadata/labels"]
          label = torch.from_numpy(metadata[index, ...])
          return (data, label)

      def __len__(self):
          return self.length

#+end_src


* SDC3: my contribution finished -> consultant
{{{h3(Tomographic imaging of the 21-cm signal)}}}

- Probe reionization process by observing the redshifted 21-cm signal $\delta T_{b} \approx n_{\text{HI}}(\theta,z)$
- Square Kilometre Array (SKA1-Low): Image sequence of the redshifted 21-cm signals at different observed frequencies
- 3D tomographic dataset a.k.a /21-cm lightcones/: 2D angles + 1D frequencies

#+ATTR_HTML: :height 400px :align left :style float:left :style margin:2px 2px 2px 200px;
[[./assets/images/sdc3a/21cm_lightcone.png]]
#+ATTR_HTML: :height 400px :align left :style float:right :style margin:2px 2px 2px 200px;
[[./assets/images/sdc3a/21cm_lightcone_slice.png]]


* ML4GLEAM: update

- first candidate was not free for the anticipated workload
- meeting with new candidate (Manuel Weiss) on 23 May


* GL3DGen

- proposal submitted to SNF Spark
  - passed pre-screening
  - awaiting response
- possible extension with MT
  - in contact with Rafael (embe)
  - may start late summer


* DL4IceH

- I was approach by a friend @ ERNI (ML consultancy) & coach from ZSC Lions
  - deep learning to improve training sessions
  - advanced sensors & expensive camera equipment
  - no idea how to use the data
- databooster proposal discussion on Mon 22 May
  - surveying literature
    - not much on work on ice hockey
    - pose tracking including hockey stick (Canadian universities)
